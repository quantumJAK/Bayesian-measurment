\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\newlabel{FirstPage}{{}{1}{}{Doc-Start}{}}
\@writefile{toc}{\contentsline {title}{TITLE}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section*.2}\protected@file@percent }
\citation{}
\@writefile{toc}{\contentsline {section}{\numberline {II}Model}{2}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Bayesian Estimation}{2}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Qubit operation and control}{2}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Reinforcement Learning}{3}{section*.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The scheme of the RL agent. The agent state is updated after each shot, and the agent decides between the estimation and the qubit operation. The agent is trained using the PPO algorithm.}}{3}{figure.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {D}Dephasing}{3}{section*.7}\protected@file@percent }
\bibdata{mainNotes}
\bibstyle{apsrev4-2}
\citation{REVTEX42Control}
\citation{apsrev42Control}
\@writefile{toc}{\contentsline {section}{\numberline {III}Metric, baselines and tests}{4}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Effect of temporal correlations}{4}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}1/f noise}{4}{section*.10}\protected@file@percent }
\newlabel{LastPage}{{}{4}{}{}{}}
\gdef \@abspage@last{4}
